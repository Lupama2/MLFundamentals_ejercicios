{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Machine Learning - 2022\n",
    "## Report 2 - Classifying with convnets\n",
    "Pablo Chehade  \n",
    "Última modificación: 25/09/2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "\n",
    "Hay que construir 2 modelos: uno con ML clásico y otro con NN. El problema es uno de clasificación de imágenes (supervisado)\n",
    "\n",
    "¿Cómo se evalúa el error? Qué parámetros se usarán?\n",
    "\n",
    "TENGO QUE PONERME A RELEER LAS CLASES DE ERROR (LA ÚLTIMA PARTE) Y DE K-MEANS. Lo voy a necesitar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importo librerías\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis Exploratorio de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargo los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "archivo = \"datasets/faces_dict.p\"\n",
    "data = pickle.load(open(archivo), \"rb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ver datos\n",
    "Hay class imbalance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separo entre train y test\n",
    "\n",
    "No podría ser un problema si justo en la partición de test caen muchas imágenes de la misma persona? Si no lo hago aleatorio, no estoy usando sin querer info. del test?\n",
    "\n",
    "Recomendación guía 3:\n",
    "t. Think about whether it would be convenient to use the stratified sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Divido el dataset entre train y test. A partir de ahora no utilizaré test\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42) ### Fijamos 20% para test y 42 es el random state para poder reproducir los resultados.\n",
    "\n",
    "#Guardo el test set en un archivo pickle\n",
    "test_set.to_pickle(\"datasets/data_test.pkl\")\n",
    "\n",
    "#Divido el train_set entre train_predictors y train_target\n",
    "train_predictors = train_set.drop(\"dosel_forestal\", axis=1)\n",
    "train_target = train_set[\"dosel_forestal\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation artificially increases the size of the training set by generating\n",
    "many realistic variants of each training instance. This reduces overfitting, making this\n",
    "a regularization technique. The generated instances should be as realistic as possible: ideally, given an image from the augmented training set, a human should not be able\n",
    "to tell whether it was augmented or not. Moreover, simply adding white noise will not\n",
    "help; the modifications should be learnable (white noise is not).\n",
    "\n",
    "Se explica bien en\n",
    "https://neptune.ai/blog/data-augmentation-in-python\n",
    "Existen librerías en Python para hacer este procedimiento casi automáticamente. Están todas explicadas en ese link\n",
    "\n",
    "Podría usar una IA para rotar caras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELO 1: Random Forest\n",
    "\n",
    "¿Por qué este modelo en particular? Corre rápido\n",
    "A priori, el modelo va a ser extremadamente malo debido a la pequeña cantidad de datos y a la gran cantidad de dimensiones (64x64?)\n",
    "\n",
    "RECOMENDACIÓN: use K-Means as a dimensionality reduction tool and train a classifier on the\n",
    "reduced set (i.e., using the distances to the centroids)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### K-MEANS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo simple inicial\n",
    "\n",
    "Creo un modelo con los parámetros por default salvo (...). Por default vale (...) e implica rápidamente overfitting\n",
    "\n",
    "* En el práctico anterior: Con los parámetros por default el modelo tiene error nulo (accuracy de 100%) está overfitteando. Cambiando el parámetro max_depth a 10, el modelo tiene un error asociado y por lo tanto no overfittea (al menos no tanto como antes). Por default la variable max_depth está en None, es decir, los nodos se expanden hasta que las leaves sean puras, de ahí el overfitting quizás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Creo el modelo\n",
    "RFmodel = RandomForestClassifier(n_jobs = -1, random_state = 42, n_estimators = 100, max_depth = 10, min_samples_split = 2, min_samples_leaf = 1)\n",
    "#Lo entreno\n",
    "RFmodel.fit(train_predictors, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation\n",
    "\n",
    "Calculo el error de validación del modelo. Uso cv=5 para que el programa corra rápido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search\n",
    "\n",
    "En el práctico anterior se discutió este modelo con detalle, junto a los parámetros que se pueden variar. En este caso se decidió variar:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tengo que poner que me devuelva el error de test para cada entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ¿Cómo depende el error de train y el error de validación con la complejidad del modelo?\n",
    "\n",
    "Para evaluar esto es necesario definir la \"complejidad del modelo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importances\n",
    "\n",
    "En el caso de Desicion Trees o Random Forest, existe una métrica los features que determina cuáles son los más importantes en definir una categoría en el caso de clasificación\n",
    "\n",
    "Intentar implementar permutation_importance.\n",
    "\n",
    "En el práctico anterior se intentó emplear permutation_importance pero no se pudo utilizar debido al gran tiempo de ejecución. En función de esto, se decidió eliminar las variables con feature importancia menor a un threshold y entrenar el modelo con los mejores parámetros encontrados anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELO 2: DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo simple inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de test y exportación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a8dfe095fce2b5e88c64a2c3ee084c8e0e0d70b23e7b95b1cfb538be294c5c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
