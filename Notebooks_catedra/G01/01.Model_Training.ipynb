{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d3f080a-9a67-43a8-8771-093d54adbdf1",
   "metadata": {},
   "source": [
    "# Model training \n",
    "En este notebook vamos a trabajar con los datos del notebook **00-Datos.ipynb** y el objetivo será entrenar  modelos sobre el set de entrenamiento obtenido para luego evaluar sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e75e87-8b73-4b28-a237-f2585a434205",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports Python\n",
    "import sys\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Imports data\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00670e03-4220-4c79-a2f7-fe1cde238063",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importo la data\n",
    "housing = pd.read_pickle(\"datasets/housing_4train.pkl\")  \n",
    "\n",
    "### Saco los valores que quiero predecir\n",
    "housing_value = housing[\"median_house_value\"].copy()\n",
    "housing = housing.drop(\"median_house_value\", axis=1) # drop labels for training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f46ad-859a-4342-b35b-c3f502671efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d7c25-ae6c-42ca-9187-28ed918ee441",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c731fd-71d9-4ddd-8169-2a8a4a9da74f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e10655c-a336-4623-946f-a8784ee9fa43",
   "metadata": {},
   "source": [
    "## Data Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e5e25-294c-4bf8-ba18-e9cfb7d4fac5",
   "metadata": {},
   "source": [
    "Una vez que ya vimos cómo es la estructura de nuestros datos y conocemos su comportamiento, nos dedicamos a transformarlos para que los algoritmos de ML que utilicemos funcionen mejor. En el caso de las variables categóricas esto consiste en generar un _ordinal enconder_ o un _OneHotEncoder_. En el caso de las variables numéricas vamos a querer que éstas tomen valores del mismo orden de magnitud y que tengan el mismo dominio. Para ésto transformamos los datos con un escaleo, en general un escaleo _normal_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b46f51f-0833-4e06-b3d8-ce7efede5e5b",
   "metadata": {},
   "source": [
    "### Numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf2606-9cb2-4935-b352-c9037dc3dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "### transformacion NORMAL de  los datos\n",
    "housing_num = housing.drop([\"ocean_proximity\"],axis = 1) ### Trabajaemos con los datos numericos, dropeamos los categoricos\n",
    "\n",
    "scaler = StandardScaler() ## Instancia de clase StandardScaler\n",
    "scaler.fit(housing_num) ### el scaler necesita saber el valor medio y desvío de cada variable, el método fit los obtiene\n",
    "\n",
    "housing_num_tr = scaler.transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd27ba-0cbc-4eb6-bdfd-c1aea58c0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f60fc3-df21-429a-9c21-3d56a54cd575",
   "metadata": {},
   "source": [
    "El resultado es un numpy array con los valores normalizados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5130a0-74d1-4014-b74c-82e79f5fd82b",
   "metadata": {},
   "source": [
    "### Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5670bc94-ff7a-4c04-9884-9a14389a52e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_tr = housing_cat_1hot.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4016666e-c623-41af-9719-0d5754ff5d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder.categories_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eba9b6-8ada-4e18-aca9-798f6f442e70",
   "metadata": {},
   "source": [
    "## Tuti junti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5afa96b-1123-4f4e-9a1c-acfe14f56384",
   "metadata": {},
   "outputs": [],
   "source": [
    "### juntamos los resultadsos numericos y los categoricos\n",
    "data_full_prepared = np.concatenate((housing_num_tr, housing_cat_tr), axis=1)\n",
    "features = list(housing_num.columns) + list(cat_encoder.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b42eae-0ecd-4269-9857-b9ecc76f0f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287693e8-48e9-465b-bfa7-e1f70dfaa9db",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a2384a-3960-4d7d-94dd-f6ee9ac55182",
   "metadata": {},
   "source": [
    "## Regresión Lineal\n",
    "\n",
    "En la regresión lineal voy a sacar los Features caegóricos porque meten mucho ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ed517e-3f1a-4621-b125-6bcaef70eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = housing_num_tr\n",
    "Y = housing_value\n",
    "lin_reg = LinearRegression() ### instancia de la clase\n",
    "lin_reg.fit(X, Y) ### Fit\n",
    "print(\"Los coeficientes de la regresión son:\\n\",lin_reg.coef_,lin_reg.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65859a-b60b-4689-a7d4-65edc1ee188d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1647a16-9e5e-43b0-b1c5-ec0e215dc450",
   "metadata": {},
   "source": [
    "### Ploteo algunos de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd3482-b1bc-49fa-a2fd-69d1e1fda77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lin_reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940529a0-2315-4cd9-836d-2ab135b935fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (24,7))\n",
    "plt.subplot(121)\n",
    "idx = 7\n",
    "#y_pred =[y for _,y in sorted(zip(X.T[idx],y_pred))]\n",
    "plt.scatter(X.T[idx],y_pred,alpha =0.5,label = \"data predicted\")\n",
    "plt.scatter(X.T[idx],Y,alpha =0.5,label = \"data\")\n",
    "\n",
    "plt.plot(X.T[idx],lin_reg.coef_[idx]*X.T[idx] + lin_reg.intercept_,color = \"red\",label = \"lineal model\")\n",
    "plt.xlabel(features[idx],fontsize= 16)\n",
    "plt.ylabel(\"housing_value\",fontsize = 16)\n",
    "plt.yticks(fontsize = 14);\n",
    "plt.xticks(fontsize = 14);\n",
    "plt.legend(fontsize = 14)\n",
    "\n",
    "plt.subplot(122)\n",
    "idx = 2\n",
    "#y_pred =[y for _,y in sorted(zip(X.T[idx],y_pred))]\n",
    "plt.scatter(X.T[idx],y_pred,alpha =0.5,label = \"data predicted\")\n",
    "plt.scatter(X.T[idx],Y,alpha =0.5,label = \"data\")\n",
    "\n",
    "plt.plot(X.T[idx],lin_reg.coef_[idx]*X.T[idx] + lin_reg.intercept_,color = \"red\",label = \"lineal model\")\n",
    "plt.xlabel(features[idx],fontsize= 16)\n",
    "plt.ylabel(\"housing_value\",fontsize = 16)\n",
    "plt.yticks(fontsize = 14);\n",
    "plt.xticks(fontsize = 14);\n",
    "plt.legend(fontsize = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9ac787-4111-4d7d-aa30-bae04a1b2158",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be4e3b7-3645-4f29-8c39-a14f89298e71",
   "metadata": {},
   "source": [
    "Los árboles de decisión son capaces de definir un valor de la variable dependiente **Y**, para diferentes interavalos y condiciones de las variables independientes **X**. En este sentido este algoritmo es capaz de hacer una regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd291d89-93af-42fd-8d3a-4c76ac6b1cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "X =  data_full_prepared\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(data_full_prepared, housing_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92e011-69f7-49e1-b4a6-2399efa47256",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_reg.predict(data_full_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29096a8-c9a5-47eb-b613-451883290811",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (24,7))\n",
    "plt.subplot(121)\n",
    "idx = 7\n",
    "#y_pred =[y for _,y in sorted(zip(X.T[idx],y_pred))]\n",
    "plt.scatter(X.T[idx],y_pred,alpha =0.5,label = \"data predicted\")\n",
    "plt.scatter(X.T[idx],Y,alpha =0.5,label = \"data\")\n",
    "\n",
    "plt.xlabel(features[idx],fontsize= 16)\n",
    "plt.ylabel(\"housing_value\",fontsize = 16)\n",
    "plt.yticks(fontsize = 14);\n",
    "plt.xticks(fontsize = 14);\n",
    "plt.legend(fontsize = 14)\n",
    "\n",
    "plt.subplot(122)\n",
    "idx = 2\n",
    "#y_pred =[y for _,y in sorted(zip(X.T[idx],y_pred))]\n",
    "plt.scatter(X.T[idx],y_pred,alpha =0.5,label = \"data predicted\")\n",
    "plt.scatter(X.T[idx],Y,alpha =0.5,label = \"data\")\n",
    "\n",
    "plt.xlabel(features[idx],fontsize= 16)\n",
    "plt.ylabel(\"housing_value\",fontsize = 16)\n",
    "plt.yticks(fontsize = 14);\n",
    "plt.xticks(fontsize = 14);\n",
    "plt.legend(fontsize = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857b1dfa-16e2-4bc7-9cd7-529208a3b2ae",
   "metadata": {},
   "source": [
    "**LOS PUNTOS PREDICHOS SON IGUALES A LOS ORIGINALES**, ALGO HUELE MAL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca68b7f-e80c-4a79-ac77-d76b96a3c1f8",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55707fc7-268f-4139-83bc-2fb4648f3533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "forest_reg.fit(data_full_prepared, housing_value)\n",
    "y_pred = forest_reg.predict(data_full_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a436f660-b85b-411b-9f3c-931b4715367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (24,7))\n",
    "plt.subplot(121)\n",
    "idx = 7\n",
    "#y_pred =[y for _,y in sorted(zip(X.T[idx],y_pred))]\n",
    "plt.scatter(X.T[idx],y_pred,alpha =0.5,label = \"data predicted\")\n",
    "plt.scatter(X.T[idx],Y,alpha =0.5,label = \"data\")\n",
    "\n",
    "plt.xlabel(features[idx],fontsize= 16)\n",
    "plt.ylabel(\"housing_value\",fontsize = 16)\n",
    "plt.yticks(fontsize = 14);\n",
    "plt.xticks(fontsize = 14);\n",
    "plt.legend(fontsize = 14)\n",
    "\n",
    "plt.subplot(122)\n",
    "idx = 2\n",
    "#y_pred =[y for _,y in sorted(zip(X.T[idx],y_pred))]\n",
    "plt.scatter(X.T[idx],y_pred,alpha =0.5,label = \"data predicted\")\n",
    "plt.scatter(X.T[idx],Y,alpha =0.5,label = \"data\")\n",
    "\n",
    "plt.xlabel(features[idx],fontsize= 16)\n",
    "plt.ylabel(\"housing_value\",fontsize = 16)\n",
    "plt.yticks(fontsize = 14);\n",
    "plt.xticks(fontsize = 14);\n",
    "plt.legend(fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af0877-8a5d-4613-819f-a6d7596c5997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a382da47-9c68-4de0-9181-a1c426802dd2",
   "metadata": {},
   "source": [
    "# Métricas en una regresión\n",
    "\n",
    "Nos interesa evaluar el desempeño de nuestro modelo en predecir los valores de una variable **Y** como función de las variables independientes **X** que definimos. Para esto existen dos funciones clásicas: \n",
    "* la raiz del error cuadrático medio (_RMSE_)\n",
    "* el error absoluto medio (_MAE_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83ca76-0bab-44c4-9035-1576f82ae4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "### Linear \n",
    "X = housing_num_tr\n",
    "\n",
    "housing_predictions = lin_reg.predict(X)\n",
    "lin_mse = mean_squared_error(housing_value, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_mae = mean_absolute_error(housing_value, housing_predictions)\n",
    "\n",
    "print(\"El MSE para el modelo lineal es: \",lin_rmse)\n",
    "print(\"El MAE es el modelo lineal es: \",lin_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad064a39-8446-4e8d-8382-e5cb665adbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Desicion Trees\n",
    "\n",
    "housing_predictions = tree_reg.predict(data_full_prepared)\n",
    "tree_mse = mean_squared_error(housing_value, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "lin_mae = mean_absolute_error(housing_value, housing_predictions)\n",
    "\n",
    "print(\"El MSE para el TreeRegressor es: \",tree_rmse)\n",
    "print(\"El MAE para el TreeRegressor es: \",tree_rmse)\n",
    "print(\"Efectivamente acá hay un overfitting, que ya habíamos visto en los plots.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355c6d16-9394-41ff-8c46-98225f440745",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest \n",
    "housing_predictions = forest_reg.predict(data_full_prepared)\n",
    "forest_mse = mean_squared_error(housing_value, housing_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_mae = mean_absolute_error(housing_value, housing_predictions)\n",
    "\n",
    "print(\"El MSE para el RandomForest es: \",forest_rmse)\n",
    "print(\"El MAE para el TreeRegressor es: \",forest_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1541b31d-4405-4ecb-9f20-c576bbe5e444",
   "metadata": {},
   "source": [
    "# CV\n",
    "\n",
    "Para evaluar el desempeño de estos modelos sin utilizar nuestro set de test podemos hacer una nueva división de la partición de training. De la misma manera que antes, separamos una porción de los datos y luego entrenamos con el resto. Lo usual es dividir a los datos en 5 o 10 subconjuntos excluyentes entre sí y separar uno como el nuevo test. Con el resultado del entrenamiento aplicamos el ajuste a los datos separados y evaluamos el modelo con una función de score, por ej MSE. \n",
    "Para ver que los resultados no dependen de la partición utilizada volvemos a hacer este procedimiento utilizando los mismos 5 o 10 subconjuntos que habíamos definido, pero ahora elejimos otro para test. Haciendo esto para cada uno de los subconjunots tendremos 5, o 10, evaluaciones del modelo con su score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4356a879-ae71-4d28-9a9b-580cf2a3ba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "### definamos una función para presentar los resultados \n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb6fbfd-cf9b-48ec-9a2a-f46ea558d92a",
   "metadata": {},
   "source": [
    "## CV Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86e575-5796-424c-a302-c7716fefe6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions = lin_reg.predict(X)\n",
    "lin_scores = cross_val_score(lin_reg, X, housing_value, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaf239e-e94e-4500-b4e5-ec00fa38aef2",
   "metadata": {},
   "source": [
    "## CV Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17344997-2229-4feb-b6f4-1c4487f449ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions = tree_reg.predict(data_full_prepared)\n",
    "scores = cross_val_score(tree_reg, data_full_prepared, housing_value,scoring=\"neg_mean_squared_error\", cv=10) ### hacemos una particion de 10\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283c675-e1d8-4769-aaf7-6b03ec344a94",
   "metadata": {},
   "source": [
    "## CV Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ff0c0-9e34-4d39-a6c1-6a50aade1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions = forest_reg.predict(data_full_prepared)\n",
    "scores = cross_val_score(forest_reg , data_full_prepared, housing_value,scoring=\"neg_mean_squared_error\", cv=10) ### hacemos una particion de 10\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6307cde-30de-44f8-853f-612a33c9c01c",
   "metadata": {},
   "source": [
    "## CONCLUSIONES\n",
    "\n",
    "Del CV que realizamos sobre los tres algoritmos que propusimos resulta que el más prometedor es el RandomForest, dado que el valor medio de su error es sistemáticament más chico que el de la regresión lineal y los árboles de decisión. Más aún, tiene menos dispersión, con lo que podemos inferir que el ajuste es similar para cada \"fold\" (partición) del cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9beafdb-6911-4805-8f06-4f771a03a916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfaea7d0-426d-4127-b34a-248b21ec241b",
   "metadata": {},
   "source": [
    "# Fine Tuning\n",
    "\n",
    "El resultado anterior nos dio como mejor candidato a los RandomForest como algoritmo para hacer nuestro ajuste. Tomando a éste como el algoritmo definitivo, podemos explorar los parámetros que definen a este algoritmo y ver si hay alguna combinación de ellos que mejoran aún más nuestro score. A los parámetros que definen al algoritmo se los suele llamar _hyperparameters_ para diferenciarlos de los otros parámetros ajustados al implementar un algoritmo. En otras palabras, los hiperparámetros son variables estructurales del algoritmo que definen de antemano cómo se va a hacer el fitteo de los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b9c06f-cdd0-4932-9b89-2476cf650c20",
   "metadata": {},
   "source": [
    "## GRIDSEARCH CV\n",
    "\n",
    "El primer acercamiento a encontrar el mejor conjunto de hiperparámetros consiste en definir una grilla de valores a evaluar y comparar los scores medios del 10-fold CV hasta encontrar el mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afbb378-0f95-4d24-85f1-1b6a90105cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(data_full_prepared, housing_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63140b75-b700-4cc0-b595-36c48ddfb82a",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856862ac-aa89-4c1a-80d6-e9e373b84669",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Los mejores parámetros son:\",grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10b6b4-d794-4627-b48b-d0606a517e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9704061-1d2b-4f1a-8d09-63f77a661a2b",
   "metadata": {},
   "source": [
    "### Veamos los resultados de cada combinación de Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9cb6f7-5beb-4c80-bf22-c576ce6bddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be96ab-34d3-4961-856b-37a0bc6b9af1",
   "metadata": {},
   "source": [
    "## RANDOM SEARCH CV\n",
    "\n",
    "En este caso en lugar de definir una grilla, exploramos muestreos de los hiperparámetros en alguna distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11a7c4f-941c-47fa-9c3f-463d174bfc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(data_full_prepared, housing_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6ff8d-d475-4f50-a5d0-0a77f9f78163",
   "metadata": {},
   "source": [
    "(OJO Tarda 2 minutos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e6130-18e7-4ab0-bfcb-b4cf928e90a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6edee52-3ace-4486-b338-c24a4a13cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rnd_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a81cceb-b108-4812-bbfa-6b40b9120a60",
   "metadata": {},
   "source": [
    "## Feature importances\n",
    "\n",
    "En el caso de Desicion Trees o Random Forest, existe una métrica sobre nuestros features que determina cuáles son los más importantes en definir una categoría en el caso de clasificación o un valor de la variable dependiente en el caso de una regresión. Veamos cómo se rankean los Features en nuestro caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd79124-9f63-4110-92e0-837690985bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "\n",
    "features = list(housing_num.columns) + list(cat_encoder.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2c5d7-e6b2-4c4d-8b80-b9d656e0e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,7))\n",
    "\n",
    "# Example data\n",
    "people = ('Tom', 'Dick', 'Harry', 'Slim', 'Jim')\n",
    "y_pos = np.arange(len(people))\n",
    "performance = 3 + 10 * np.random.rand(len(people))\n",
    "error = np.random.rand(len(people))\n",
    "\n",
    "ax.barh(features, feature_importances, align='center')\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.xticks(fontsize = 14)\n",
    "ax.set_xlabel('Feature Importance',fontsize = 16)\n",
    "ax.grid()\n",
    "#ax.set_title('How fast do you want to go today?')\n",
    "#ax.set_ticklabels([\"$%dk\"%(round(v/1000)) for v in tick_values], fontsize=14)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8448558-4a57-4fc4-b10f-95e1cc21b330",
   "metadata": {},
   "source": [
    "# Modelo final y evaluación en TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a41ee15-933c-423a-b292-f9ec47d90c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defino el modelo final como el mejor entre grid y rnd\n",
    "final_model = rnd_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3930e7-8e39-4b8e-a5a0-890811bf564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_test = pd.read_pickle(\"datasets/housing_test.pkl\")\n",
    "X_test = housing_test.drop(\"median_house_value\", axis=1)\n",
    "Y_test = housing_test[\"median_house_value\"].copy()\n",
    "\n",
    "## Hago las nuevas variables\n",
    "\n",
    "X_test[\"rooms_per_household\"] = X_test[\"total_rooms\"]/X_test[\"households\"]\n",
    "X_test[\"bedrooms_per_room\"] = X_test[\"total_bedrooms\"]/X_test[\"total_rooms\"]\n",
    "X_test[\"population_per_household\"]=X_test[\"population\"]/X_test[\"households\"]\n",
    "\n",
    "\n",
    "### datos para la distancia.\n",
    "p0 = (-124.55,38)\n",
    "p1 = (-118.5, 32.5)\n",
    "m = (p1[1]-p0[1])/(p1[0]-p0[0])\n",
    "b = p0[1]-m*p0[0]\n",
    "X_test[\"coast_distance\"] =  abs(m*X_test[\"longitude\"] - X_test[\"latitude\"] + b)/np.sqrt(m**2+1)\n",
    "\n",
    "\n",
    "### Relleno los NANS con medias\n",
    "\n",
    "median_totbed = X_test[\"total_bedrooms\"].median()\n",
    "median_bedroom = X_test[\"bedrooms_per_room\"].median()\n",
    "\n",
    "### \n",
    "\n",
    "X_test[\"total_bedrooms\"].fillna(median_totbed, inplace=True)\n",
    "X_test[\"bedrooms_per_room\"].fillna(median_bedroom, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b6953-7241-400f-8a77-e8c7f6c3f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82812b2a-f2fc-4154-8499-d04302af3551",
   "metadata": {},
   "outputs": [],
   "source": [
    "### transformacion NORMAL de  los X\n",
    "test_num = X_test.drop([\"ocean_proximity\"],axis = 1) ### Trabajaemos con los datos numericos, dropeamos los categoricos\n",
    "scaler = StandardScaler() ## Instancia de clase StandardScaler\n",
    "scaler.fit(test_num) ### el scaler necesita saber el valor medio y desvio de cada variable, el método fit los obtiene\n",
    "test_num_tr = scaler.transform(test_num)\n",
    "\n",
    "test_cat = X_test[[\"ocean_proximity\"]]\n",
    "cat_encoder = OneHotEncoder()\n",
    "test_cat_1hot = cat_encoder.fit_transform(test_cat)\n",
    "test_cat_tr = test_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce8177b0-1406-4cc5-9675-27f564c63c9f",
   "metadata": {},
   "source": [
    "### Acá por mala suerte la última categoría no apareció, se lo agregamos con un 0 en cada fila.\n",
    "test_cat_tr_ = [  for x in test_cat_tr]\n",
    "#test_cat_tr_ = np.array(test_cat_tr_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c3c16a-f85b-4298-978d-b035263fb354",
   "metadata": {},
   "outputs": [],
   "source": [
    "### juntamos los resultadsos numericos y los categoricos\n",
    "data_test_prepared = np.concatenate((test_num_tr, test_cat_tr), axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99f6a934-d154-428a-bb93-b529476546c3",
   "metadata": {},
   "source": [
    "test_cat_tr_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe078c-d271-468b-8a40-189cfc302dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### tran\n",
    "\n",
    "final_predictions = final_model.predict(data_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(Y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22ffea1-c75e-4e84-9865-8d27a6359570",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215184a1-4adb-4cbf-b296-4a0083d46be2",
   "metadata": {},
   "source": [
    "**ESTE ES EL ERROR FINAL DE NUESTRO MODELO.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e4709-1888-4ce7-a035-ab43c256eb70",
   "metadata": {},
   "source": [
    "# Exporto el modelo para producción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227b3a6-90d2-4aa7-b002-ba233777c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_model.p\",\"wb\") as f:\n",
    "    pickle.dump(final_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1148b-afb2-4c3f-9a90-7330ba71ce9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Introduccion_al_ML_IB')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0aa1956f6385f32f27cbf130d1061fb9b6a3751ba793bfb23dacf8373af4031e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
